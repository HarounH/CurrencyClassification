from __future__ import print_function
'''
	@author Haroun

	This file provides utilities for handling data.
'''
# The usual imports.
import sys,os
import datetime as dt, random, pickle
import numpy as np
import pandas as pd
import pdb
import matplotlib.pyplot as plt


# This class has not been made yet.
class DataFile:
	def __init__(self):
		pass

'''
	@params src The file which contains the data
	@params dstFileNameGenerator A function which takes in a chunkId and returns a filename to put the data into.
	@params nLinesPerChunk selfexplanatory
	@method This file splits up the src into a bunch of files (chunks) each with nLinesPerChunk
'''
def fileChunker(src, dstFileNameGenerator, nLinesPerChunk):
	with open(src,'rb', 1) as f: # the '1' is buffering thingy.
		totalLines = 0
		chunkIdx = 0
		nLinesThisChunk = 0
		chunk = ''
		print('chunkIdx=' + str(chunkIdx))
		for line in f:
			if nLinesThisChunk==nLinesPerChunk:
				print('nLinesThisChunk=' + str(nLinesThisChunk), end='\n')
				nLinesThisChunk = 0
				# Write the data.
				with open(dstFileNameGenerator(chunkIdx), 'wb') as dst:
					dst.write(chunk)
				chunkIdx += 1
				chunk = ''
				print('chunkIdx=' + str(chunkIdx))
			else:
				print('nLinesThisChunk=' + str(nLinesThisChunk), end='\r')
			nLinesThisChunk += 1
			totalLines += 1
			chunk += (line if line.endswith('\n') else line+'\n')
		print('\nTotal lines=' + str(totalLines))
	return
'''
	Similar to fileChunker but it removes column0 and also fixes the labels to be 1vs all based on the label input.
'''
def OneVsAllChunker(src, dstFileNameGenerator, nLinesPerChunk, label):
	with open(src,'rb', 1) as f: # the '1' is buffering thingy.
		totalLines = 0
		chunkIdx = 0
		nLinesThisChunk = 0
		nPositivesThisChunk = 0
		chunk = ''
		print('chunkIdx=' + str(chunkIdx))
		for line in f:

			if nLinesThisChunk==nLinesPerChunk:
				print('nLinesThisChunk, nPositivesThisChunk=' + str(nLinesThisChunk) + ',' + str(nPositivesThisChunk), end='\n')
				nLinesThisChunk = 0
				nPositivesThisChunk = 0
				# Write the data.
				with open(dstFileNameGenerator(chunkIdx), 'wb') as dst:
					dst.write(chunk)
				chunkIdx += 1
				chunk = ''
				print('chunkIdx=' + str(chunkIdx))
			else:
				print('nLinesThisChunk=' + str(nLinesThisChunk), end='\r')
			nLinesThisChunk += 1
			totalLines += 1
			
			# This is the only line that is different from the function above.
			toks = line.split(',')
			x = toks[2:]
			y = int(toks[1])
			if y==label:
				y = 1
				nPositivesThisChunk += 1
			else:
				y = -1
			chunk += str(y) + ',' + ','.join(x).rstrip('\r\n') + '\n'
		print('\nTotal lines=' + str(totalLines))
		
		# bloody edge cases :(
		if chunk != '':
			with open(dstFileNameGenerator(chunkIdx), 'wb') as dst:
				dst.write(chunk)
				
	return

'''
	This file loads multiple chunks and puts them into a single pandas dataframe.
	It then returns said dataframe.

	@params chunkFileNames a list of files names, each of which is a chunk (generated by fileChunker, OneVsAllChunker etc)
	@returns pd.concat(frames) this is all the chunks combined into a single dataframe.

	This function is oblivious to chunk format as long as they are consistent.
'''
def loadChunks(chunkFileNames):
	frames = []
	print('about to start loading chunks')
	for filename in chunkFileNames:
		frames.append(pd.read_csv(filename, header=None))
		print('loaded ' + filename)
	return pd.concat(frames, ignore_index=True)

'''
	This function requires a fixed format.

	It takes a dataframe and converts it into a format that is amicable to using LDKL, as developed by Manik Verma and co.

	@params dataframe
		Format:
			columns[0] is the label ... either 1, or -1
			columns[1...D] are the feature dimensions.

	@params outputFilename the file to which shit ust be outputted.
		file format is as described by README in LDKL1.1
		For ease of reading, it is:
			Line1: N D
			Line2...N+1 : 
'''	
def LDKLFileFomatDump(dataframe, outputfilename):
	(N,D) = dataframe.shape
	D-=1
	print('about to start writing dataframe')
	with open(outputfilename,'wb') as f:
		f.write(str(N) + ' ' + str(D) + '\n')

	dataframe.to_csv(outputfilename, sep=' ', header=False, index=False, chunksize=650, mode='a')
	
	print('shape=' + str(dataframe.shape))
	return
	
if __name__ == '__main__':
	# Make chunks
	# OneVsAllChunker('../data/RAW_PIXELS_train.csv',lambda x: ('../data/trainChunk/' + sys.argv[1] + 'raw_pixels' + str(x) + '.csv'), 650, int(sys.argv[1]))
	
	# LDKLify training data
	# LDKLFileFomatDump(loadChunks(['../data/trainChunk/1raw_pixels' + str(i) + '.csv' for i in [0, 21, 31, 38] ]) , '../data/ldkl_1_train.txt')
	
	# LDKLify validation data
	LDKLFileFomatDump(loadChunks(['../data/trainChunk/1raw_pixels' + str(i) + '.csv' for i in [1, 22, 32, 37] ]) , '../data/ldkl_1_validation.txt')